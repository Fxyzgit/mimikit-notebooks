{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mimikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Source Code for Redundance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit.freqnet import FreqNet\n",
    "from mimikit.data import Database\n",
    "from mimikit.utils import audio, signal\n",
    "from mimikit import NeptuneConnector\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20, 6)\n",
    "\n",
    "\n",
    "# functions we need to compute the redundance rate\n",
    "\n",
    "\n",
    "def cosine_similarity(X, Y, eps=1e-10):\n",
    "    \"\"\"\n",
    "    safely computes the cosine similarity between matrices X and Y.\n",
    "\n",
    "    Shapes:\n",
    "    -------\n",
    "    X : (*, N, D)\n",
    "    Y : (*, M, D)\n",
    "    D_xy : (*, N, M)\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    The need for this function arises from the fact that torch.nn.CosineSimilarity only computes the \n",
    "    diagonal of D_xy, as in cosine_sim(output, target) \n",
    "    \"\"\"\n",
    "    if not isinstance(eps, torch.Tensor):\n",
    "        eps = torch.tensor(eps).to(X)\n",
    "        \n",
    "    dot_prod = torch.matmul(X, Y.transpose(-2, -1))\n",
    "    norms = torch.norm(X, p=2, dim=-1).unsqueeze_(-1) * torch.norm(Y, p=2, dim=-1).unsqueeze_(-2)\n",
    "    cos_theta = dot_prod / torch.maximum(norms, eps)    \n",
    "    return cos_theta\n",
    "\n",
    "def angular_distance(X, Y, eps=1e-10):\n",
    "    \"\"\"\n",
    "    angular distance is a valid distance metric based on the cosine similarity\n",
    "    see https://en.wikipedia.org/wiki/Cosine_similarity#Angular_distance_and_similarity\n",
    "    \n",
    "    Shapes:\n",
    "    -------\n",
    "    X : (*, N, D)\n",
    "    Y : (*, M, D)\n",
    "    D_xy : (*, N, M)\n",
    "    \"\"\"\n",
    "    if not isinstance(eps, torch.Tensor):\n",
    "        eps = torch.tensor(eps).to(X)\n",
    "        \n",
    "    def safe_acos(x):\n",
    "        # torch.acos returns nan near -1 and 1... see https://github.com/pytorch/pytorch/issues/8069\n",
    "        return torch.acos(torch.clamp(x, min=-1+eps/2, max=1-eps/2))\n",
    "\n",
    "    have_negatives = torch.any(X < 0) or torch.any(Y < 0)\n",
    "    cos_theta = cosine_similarity(X, Y, eps)\n",
    "    \n",
    "    pi = torch.acos(torch.zeros(1)).item() * 2\n",
    "    D_xy = (1 + int(not have_negatives)) * safe_acos(cos_theta) / pi\n",
    "    \n",
    "    return D_xy\n",
    "\n",
    "\n",
    "def nearest_neighbor(X, Y):\n",
    "    \"\"\"\n",
    "    computes nearest neighbor by angular distance\n",
    "    \"\"\"\n",
    "    D_xy = angular_distance(X, Y)\n",
    "    dists, nn = torch.min(D_xy, dim=-1)\n",
    "    return dists, nn\n",
    "\n",
    "\n",
    "def torch_frame(x, frame_size, hop_length):\n",
    "    \"\"\"\n",
    "    helper to reshape an array into frames\n",
    "    \"\"\"\n",
    "    N = x.size(-1)\n",
    "    org_size = x.size()[:-1]\n",
    "    tmp_0 = np.prod(tuple(org_size))\n",
    "    new_dims = (1 + int((N - frame_size) / hop_length), frame_size)\n",
    "    framed = torch.as_strided(x.reshape(-1, N), (tmp_0, *new_dims), (N, hop_length, 1))\n",
    "    return framed.reshape(*org_size, *new_dims)\n",
    "\n",
    "\n",
    "def repeat_rate(x, frame_size, hop_length):\n",
    "    \"\"\"\n",
    "    frames x and compute repeat-rate per frame\n",
    "    \"\"\"\n",
    "    framed = torch_frame(x, frame_size, hop_length)\n",
    "    uniques = torch.tensor([torch.unique(row).size(0) for row in framed.reshape(-1, framed.size(-1))])\n",
    "    return (1 - (uniques-1) / (frame_size-1)).reshape(framed.size()[:-1], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/redundance-rate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DB & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_name = \"experiment-2/\"\n",
    "\n",
    "# function to filter experiment (must return True or False)\n",
    "# `exp_row` is a dict with the column names as keys and the values are the exp's values (no .y!)\n",
    "def is_match(exp_row):\n",
    "    return \"Lachenmann\" in exp_row[\"DB\"] or \"Schweifel\" in exp_row[\"DB\"]\n",
    "\n",
    "\n",
    "nc = NeptuneConnector(user=\"k-tonal\", setup={\"project\": project_name})\n",
    "prj = nc.get_project(\"project\")\n",
    "if \"exps\" not in globals():\n",
    "    exps = [(exp, exp.get_logs()) for exp in prj.get_experiments()\n",
    "            if is_match({k: v.y for k, v in exp.get_logs().items()})]\n",
    "dbs, mdls = {}, {}\n",
    "for exp, log in exps:\n",
    "    nc.setup[exp.id + \"-db\"] = log[\"db-id\"].y\n",
    "    nc.setup[exp.id] = project_name + exp.id\n",
    "    if not os.path.exists(log[\"db-name\"].y):\n",
    "        nc.download_database(exp.id + \"-db\", log[\"db-name\"].y)\n",
    "    if not os.path.exists(exp.id + \"/states\"):\n",
    "        nc.download_experiment(exp.id, artifacts=\"states/\")\n",
    "\n",
    "    dbs[exp.id] = Database(log[\"db-name\"].y)\n",
    "    iloc = log[\"db-iloc\"].y\n",
    "    def get_model(id, epoch, iloc=iloc):\n",
    "        if iloc:\n",
    "            data = dbs[id].fft.get(dbs[id].metadata.iloc[eval(iloc)])\n",
    "        else:\n",
    "            data = dbs[id].fft\n",
    "        return FreqNet.load_from_checkpoint(id + \"/states/epoch=%i.ckpt\" % epoch,\n",
    "                                     data_object=data)\n",
    "    mdls[exp.id] = get_model\n",
    "\n",
    "mdls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = \"EX2-200\"\n",
    "epoch = 99\n",
    "\n",
    "db, model = dbs[exp_id], mdls[exp_id](exp_id, epoch)\n",
    "db.fft.attrs, model.data.shape, model.hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_length = 64\n",
    "n_steps = 2048\n",
    "\n",
    "\n",
    "# prompt index :\n",
    "\n",
    "i = randint(0, model.data.shape[0] - prompt_length)\n",
    "\n",
    "\n",
    "output = model.generate(model.data[i:i+prompt_length], time_domain=False, n_steps=n_steps).squeeze(0)\n",
    "wrt = torch.from_numpy(model.data[i+prompt_length:i+prompt_length+n_steps]).to(output).unsqueeze(0)\n",
    "\n",
    "audio(output.squeeze().numpy().T, hop_length=db.fft.attrs[\"hop_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute RR over time at mutiple levels for a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nearest neighbors:\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, neighbs = nearest_neighbor(output[:, prompt_length:], wrt)\n",
    "\n",
    "\n",
    "# for plotting multiple levels of locality, we have one hop_length for several frame_sizes\n",
    "frame_size = (8, 64, 128)\n",
    "hop_length = 2\n",
    "\n",
    "\n",
    "# compute rr and plot\n",
    "\n",
    "for fs in frame_size:\n",
    "    with torch.no_grad():\n",
    "        r = repeat_rate(neighbs, fs, hop_length)\n",
    "    plt.plot(r.squeeze().cpu().numpy(), label=\"frame size = \"+str(fs))\n",
    "    \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1, 1.1])\n",
    "plt.legend()\n",
    "plt.ylabel('Redundance Rate')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Local Redundance Rate over Time')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Outputs and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#######################################\n",
    "\n",
    "# we take one prompt every \"stride\" index :\n",
    "stride = 16\n",
    "\n",
    "n_steps = 200\n",
    "prompt_length = 64\n",
    "\n",
    "batch_size = 300\n",
    "\n",
    "# params for RR :\n",
    "\n",
    "frame_sizes = (8, 64, 128)\n",
    "hop_length = 2\n",
    "\n",
    "#######################################\n",
    "\n",
    "all_indices = np.arange(0, model.data.shape[0] - prompt_length, stride)\n",
    "current_step = np.zeros_like(all_indices)\n",
    "\n",
    "loader = DataLoader(all_indices, shuffle=False, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "scores = np.ones((all_indices.shape[0], len(frame_sizes)))\n",
    "last_outputs = []\n",
    "# compute\n",
    "\n",
    "for indices in tqdm(loader):\n",
    "\n",
    "    prompts = torch.from_numpy(model.data[indices[0]:indices[-1]+prompt_length])\n",
    "    wrts = torch.from_numpy(model.data[min(indices[0]+prompt_length, model.data.shape[0]-stride*indices.shape[0]-n_steps):indices[-1]+prompt_length+n_steps])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        D = prompts.size(-1)\n",
    "        prompts = torch.as_strided(prompts, size=(indices.shape[0], prompt_length, D),\n",
    "                                   stride=(stride * D, D, 1))\n",
    "        wrts = torch.as_strided(wrts, size=(indices.shape[0], n_steps, D),\n",
    "                                stride=(stride * D, D, 1))\n",
    "\n",
    "    outputs = model.generate(prompts, time_domain=False, n_steps=n_steps).squeeze(0)\n",
    "    last_outputs += [outputs[:, -model.receptive_field():].clone()]\n",
    "    with torch.no_grad():\n",
    "        _, neighbs = nearest_neighbor(outputs[:, prompt_length:], wrts)\n",
    "\n",
    "    for i, fs in enumerate(frame_sizes):\n",
    "        with torch.no_grad():\n",
    "            r = repeat_rate(neighbs, fs, hop_length).mean(dim=-1)\n",
    "\n",
    "    scores[indices // stride, i] = r.squeeze().numpy()\n",
    "    current_step[indices // stride] = n_steps\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_outputs = torch.cat(last_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32, 8))\n",
    "for i, fs in enumerate(frame_sizes):\n",
    "    plt.plot(all_indices[:], scores[:, i], label=\"frame size = \"+str(fs))\n",
    "    \n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1, 1.1])\n",
    "plt.ylabel('Mean Local Redundance Rate')\n",
    "plt.xlabel('Prompt Index')\n",
    "plt.title(\"Output's Scores\")\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate further and compute scores for the best indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrts(model, indices, n_steps):\n",
    "    wrts = np.stack([model.data[min(i, model.data.shape[0]-n_steps):i+n_steps] for i in indices])\n",
    "    return torch.from_numpy(wrts)\n",
    "\n",
    "def gen_and_score(model, prompts, indices, n_steps, frame_sizes=(8, 16, 32), hop_length=2):\n",
    "\n",
    "    this_scores = np.ones((prompts.shape[0], len(frame_sizes)))\n",
    "    outputs = model.generate(prompts, time_domain=False, n_steps=n_steps).squeeze(0)\n",
    "    last_outputs = outputs[:, -model.receptive_field():].clone()\n",
    "    wrts = get_wrts(model, indices, n_steps)\n",
    "    with torch.no_grad():\n",
    "        _, neighbs = nearest_neighbor(outputs[:, prompts.size(1):], wrts)\n",
    "\n",
    "    for i, fs in enumerate(frame_sizes):\n",
    "        with torch.no_grad():\n",
    "            r = repeat_rate(neighbs, fs, hop_length).mean(dim=-1)\n",
    "\n",
    "        this_scores[:, i] = r.squeeze().numpy()\n",
    "\n",
    "    return this_scores, last_outputs\n",
    "\n",
    "### PLAY WITH THESE : ######\n",
    "\n",
    "n_steps = 500\n",
    "n_times = 10\n",
    "# index of the frame_size to use for threshold :\n",
    "frame_sizes_level = 2\n",
    "# only consider indices with scores below :\n",
    "candidates_threshold = .75\n",
    "\n",
    "############################\n",
    "\n",
    "for _ in tqdm(range(n_times)):\n",
    "\n",
    "    # threshold\n",
    "    candidates = np.arange(scores.shape[0])[scores[:, frame_sizes_level] < candidates_threshold]\n",
    "\n",
    "    if not np.any(candidates):\n",
    "        break\n",
    "\n",
    "    # n bests\n",
    "    idx = np.argsort(scores[candidates, 0])[:128]\n",
    "    idx = candidates[idx]\n",
    "\n",
    "    new_scores, new_outs = gen_and_score(model, last_outputs[idx], all_indices[idx], n_steps)\n",
    "    # update scores\n",
    "    scores[idx] = (scores[idx] * current_step[idx][:, None] + (new_scores * n_steps)) / (current_step[idx][:, None] + n_steps)\n",
    "    current_step[idx] += n_steps\n",
    "    last_outputs[idx] = new_outs\n",
    "    \n",
    "\"200 best indices are \", scores[:, frame_sizes_level].argsort()[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32, 8))\n",
    "for i, fs in enumerate(frame_sizes):\n",
    "    plt.plot(all_indices[:], scores[:, i], label=\"frame size = \"+str(fs))\n",
    "    \n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1, 1.1])\n",
    "plt.ylabel('Mean Local Redundance Rate')\n",
    "plt.xlabel('Prompt Index')\n",
    "plt.title(\"Output's Scores\")\n",
    "\n",
    "##### PICK AN INDEX #####\n",
    "index = 123\n",
    "########################\n",
    "\n",
    "best_i = index * stride\n",
    "print(\"prompt_index\", best_i, \"with scores\", scores[index], \"generated\", current_step[index], \"steps\")\n",
    "\n",
    "prompt = model.data[best_i:best_i+64]\n",
    "out = model.generate(prompt, time_domain=True, n_steps=5000).squeeze().numpy()\n",
    "\n",
    "audio(out, hop_length=db.fft.attrs[\"hop_length\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
