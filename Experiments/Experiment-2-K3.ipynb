{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mimikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit.freqnet import FreqNet\n",
    "from mimikit.data import Database\n",
    "from mimikit.utils import audio\n",
    "from mimikit import get_trainer, NeptuneConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune :\n",
    "\n",
    "nep_con = NeptuneConnector(user=\"k-tonal\",\n",
    "                           setup=dict(db=\"data-and-base-notebooks/DAT-27\",\n",
    "                                      model=\"experiment-2-K3\"))\n",
    "\n",
    "db_name = \"genoel-mix.h5\"\n",
    "\n",
    "# paths\n",
    "\n",
    "path_to_db = \"./\" + db_name\n",
    "path_to_model = \"./experiment-2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your data\n",
    "\n",
    "db = nep_con.download_database(\"db\", db_name)\n",
    "db.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying Parameters\n",
    "\n",
    "we only try different layer-configurations together with the fastest possible params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # baselines :\n",
    "    \n",
    "    0: dict(n_layers=(1,)),\n",
    "    1: dict(n_layers=(2,)),\n",
    "    2: dict(n_layers=(3,)),\n",
    "    3: dict(n_layers=(4,)),\n",
    "    4: dict(n_layers=(5,)),\n",
    "    \n",
    "    # we change the compression-rate without changing the length of input_sequence to the net \n",
    "    # ==> thus we have more layers for as many input_time_steps :\n",
    "    \n",
    "    5: dict(n_layers=(1, 1, 1)),  ## == (2,)\n",
    "    6: dict(n_layers=(1, 2, 2)),  ## == (3, )\n",
    "    7: dict(n_layers=(1, 1, 1, 1, 1, 1, 1,)), ## == (3, )\n",
    "    8: dict(n_layers=(1, 3, 3)),  ## == (4, )\n",
    "    9: dict(n_layers=(1, 1, 2, 2, 3)),  ## == (4, )\n",
    "    10: dict(n_layers=(3, 2, 2, 1, 1,)),  ## == (4, )\n",
    "    11: dict(n_layers=(1, 4, 4)),  ## == (5, )\n",
    "    12: dict(n_layers=(1, 1, 3, 3, 4)),  ## == (5, )\n",
    "    13: dict(n_layers=(1, 3, 1, 3, 4)),  ## == (5, )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a parametrization :\n",
    "\n",
    "PARAMS_INDEX = 9\n",
    "\n",
    "# if you want ilocs (files in the db) put them in this list :\n",
    "ILOCS = []\n",
    "\n",
    "\n",
    "# build a model and its trainer\n",
    "\n",
    "model = FreqNet(\n",
    "    data_object=db.fft.get(db.metadata.iloc[ILOCS]) if any(ILOCS) else db.fft,\n",
    "    splits=[.85, .15],\n",
    "    model_dim=1024,\n",
    "    kernel_size=3,\n",
    "    # because we have a lot of layers, we try to speed things up :\n",
    "    groups=2,\n",
    "    with_skip_conv=False,\n",
    "    with_residual_conv=False,\n",
    "    accum_outputs=0,\n",
    "    concat_outputs=0,\n",
    "    pad_input=0,\n",
    "    **params[PARAMS_INDEX]\n",
    "     )\n",
    "\n",
    "trainer = get_trainer(model=model,\n",
    "                     max_epochs=100,\n",
    "                      \n",
    "                     # add a mid-training checkpoint :\n",
    "                     epochs=[49, 99],\n",
    "                      \n",
    "                     # when groups=2, precision=32 is faster than precision=16...\n",
    "                     precision=32,\n",
    "                     \n",
    "                      root_dir=path_to_model,\n",
    "                     neptune_connector=nep_con,\n",
    "                     )\n",
    "\n",
    "# log some infos to the neptune experiment :\n",
    "\n",
    "nept_exp = [exp for exp in trainer.logger.experiment if exp.__class__.__name__ == \"Experiment\"]\n",
    "if any(nept_exp):\n",
    "    nept_exp[0].append_tags(\"INDEX=\" + str(PARAMS_INDEX),\n",
    "                         \"precision=32\",\n",
    "                         \"FreqNet\",\n",
    "                         \"db=\"+db_name,\n",
    "                         \"db_size=\" + str(model.data.shape[0]),\n",
    "                         \"receptive_field=\" + str(model.receptive_field()),\n",
    "                         \"total_n_layers=\" + str(sum(params[PARAMS_INDEX][\"n_layers\"])))\n",
    "    \n",
    "    nept_exp[0].log_text(\"DB\", db_name)\n",
    "    nept_exp[0].log_text(\"INDEX\", str(PARAMS_INDEX))\n",
    "    nept_exp[0].log_text(\"RF\", str(model.receptive_field()))\n",
    "    nept_exp[0].log_text(\"N_LAYERS\", str(sum(params[PARAMS_INDEX][\"n_layers\"])))\n",
    "    \n",
    "    nept_exp[0].log_text(\"db-name\", db_name)\n",
    "    nept_exp[0].log_text(\"db-id\", nep_con.setup[\"db\"])\n",
    "    nept_exp[0].log_text(\"db-iloc\", str(ILOCS) if any(ILOCS) else \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Train :\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "# upload checkpoints and logs\n",
    "\n",
    "nep_con.upload_model(\"model\", model, artifacts=(\"states\", \"logs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try some prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "n_prompts = 2\n",
    "prompts_indices = [randint(0, model.data.shape[0]-64) for _ in range(n_prompts)]\n",
    "\n",
    "for n, i in enumerate(prompts_indices):\n",
    "    output = model.generate(model.data[i:i+64],\n",
    "                            n_steps=2048)\n",
    "    \n",
    "    print(\"prompt\", n, \"index\", i)\n",
    "    \n",
    "    audio(output.squeeze().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log a prompt you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1234\n",
    "\n",
    "model.log_audio(\"prompt=\" + str(i), model.generate(model.data[i:i+64], n_steps=2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download an already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nep_con.setup[\"trained\"] = \"model-upload-test/MOD-134\"\n",
    "\n",
    "nep_con.download_experiment(\"trained\", destination=path_to_model, artifacts=\"states/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the \"X\" in the next line with the (saved) epoch you want to load\n",
    "\n",
    "path_to_ckpt = path_to_model + \"MOD-134/states/epoch=X.ckpt\"\n",
    "\n",
    "model = FreqNet.load_from_checkpoint(path_to_ckpt, data_object=db.fft)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Experiment-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
