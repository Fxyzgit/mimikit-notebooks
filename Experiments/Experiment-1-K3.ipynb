{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mimikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit.freqnet import FreqNet\n",
    "from mimikit.data import Database\n",
    "from mimikit.utils import audio\n",
    "from mimikit import get_trainer, NeptuneConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune :\n",
    "\n",
    "nep_con = NeptuneConnector(user=\"k-tonal\",\n",
    "                           setup=dict(db=\"data-and-base-notebooks/DAT-27\",\n",
    "                                      model=\"experiment-1-B\"))\n",
    "\n",
    "db_name = \"genoel-mix.h5\"\n",
    "\n",
    "# paths\n",
    "\n",
    "path_to_db = \"./\" + db_name\n",
    "path_to_model = \"./model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your data\n",
    "\n",
    "db = nep_con.download_database(\"db\", db_name)\n",
    "db.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # from quick to slow with accum left:\n",
    "    0: dict(\n",
    "        with_skip_conv=False,\n",
    "        with_residual_conv=False,\n",
    "        pad_input=0,\n",
    "        accum_outputs=1,\n",
    "    ),\n",
    "    1: dict(\n",
    "        with_skip_conv=False,\n",
    "        with_residual_conv=True,\n",
    "        pad_input=0,\n",
    "        accum_outputs=1,\n",
    "    ),\n",
    "    2:  dict(\n",
    "        with_skip_conv=True,\n",
    "        with_residual_conv=False,\n",
    "        pad_input=0,\n",
    "        accum_outputs=1,\n",
    "    ),\n",
    "    3:  dict(\n",
    "        with_skip_conv=True,\n",
    "        with_residual_conv=True,\n",
    "        pad_input=0,\n",
    "        accum_outputs=1,\n",
    "    ),\n",
    "    # quick with learned_padding left or right\n",
    "    4: dict(\n",
    "        with_skip_conv=False,\n",
    "        with_residual_conv=False,\n",
    "        pad_input=1,\n",
    "        learn_padding=True,\n",
    "    ),\n",
    "    5: dict(\n",
    "        with_skip_conv=False,\n",
    "        with_residual_conv=False,\n",
    "        pad_input=-1,\n",
    "        learn_padding=True,\n",
    "    ),\n",
    "    # skips with learned_padding left or right\n",
    "    6:  dict(\n",
    "        with_skip_conv=True,\n",
    "        with_residual_conv=False,\n",
    "        pad_input=1,\n",
    "        learn_padding=True,\n",
    "    ),\n",
    "    7:  dict(\n",
    "        with_skip_conv=True,\n",
    "        with_residual_conv=False,\n",
    "        pad_input=-1,\n",
    "        learn_padding=True,\n",
    "    ),\n",
    "    # full with learned_padding left or right\n",
    "    8: dict(\n",
    "        with_skip_conv=True,\n",
    "        with_residual_conv=True,\n",
    "        pad_input=1,\n",
    "        learn_padding=True,\n",
    "    ),\n",
    "    9: dict(\n",
    "        with_skip_conv=True,\n",
    "        with_residual_conv=True,\n",
    "        pad_input=-1,\n",
    "        learn_padding=True,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a parametrization :\n",
    "\n",
    "PARAMS_INDEX = 9\n",
    "\n",
    "# if you want ilocs (files in the db) put them in this list :\n",
    "ILOCS = []\n",
    "\n",
    "\n",
    "# build a model and its trainer\n",
    "\n",
    "model = FreqNet(\n",
    "    data_object=db.fft.get(db.metadata.iloc[ILOCS]) if any(ILOCS) else db.fft,\n",
    "    splits=[.85, .15],\n",
    "     model_dim=1024,\n",
    "     groups=1,\n",
    "     n_layers=(4,),\n",
    "    kernel_size=3,\n",
    "    **params[PARAMS_INDEX]\n",
    "     )\n",
    "\n",
    "trainer = get_trainer(model=model,\n",
    "                     max_epochs=100,\n",
    "                     epochs=[99],\n",
    "                     # try everything in 16-bits precision\n",
    "                     precision=16,\n",
    "                     root_dir=path_to_model,\n",
    "                     neptune_connector=nep_con,\n",
    "                     )\n",
    "\n",
    "# log some infos to the neptune experiment :\n",
    "\n",
    "nept_exp = [exp for exp in trainer.logger.experiment if exp.__class__.__name__ == \"Experiment\"]\n",
    "if any(nept_exp):\n",
    "    nept_exp[0].append_tags(\"INDEX=\" + str(PARAMS_INDEX),\n",
    "                         \"precision=16\",\n",
    "                         \"FreqNet\",\n",
    "                         \"db_size=\" + str(model.data.shape[0]),\n",
    "                         *[k + \"=\" + str(v) for k, v in params[PARAMS_INDEX].items()])\n",
    "    nept_exp[0].log_text(\"DB\", db_name)\n",
    "    nept_exp[0].log_text(\"INDEX\", str(PARAMS_INDEX))\n",
    "    nept_exp[0].log_text(\"db-name\", db_name)\n",
    "    nept_exp[0].log_text(\"db-id\", nep_con.setup[\"db\"])\n",
    "    nept_exp[0].log_text(\"db-iloc\", str(ILOCS) if any(ILOCS) else \"\")\n",
    "\n",
    "# Train :\n",
    "\n",
    "trainer.fit(model)\n",
    "\n",
    "# upload checkpoints and logs\n",
    "\n",
    "nep_con.upload_model(\"model\", model, artifacts=(\"states\", \"logs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try some prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "n_prompts = 2\n",
    "prompts_indices = [randint(0, model.data.shape[0]-64) for _ in range(n_prompts)]\n",
    "\n",
    "for n, i in enumerate(prompts_indices):\n",
    "    output = model.generate(model.data[i:i+64],\n",
    "                            n_steps=2048)\n",
    "    \n",
    "    print(\"prompt\", n, \"index\", i)\n",
    "    \n",
    "    audio(output.squeeze().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log a prompt you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1234\n",
    "\n",
    "model.log_audio(\"prompt=\" + str(i), model.generate(model.data[i:i+64], n_steps=2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download an already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nep_con.setup[\"trained\"] = \"experiment-1-B/MOD-134\"\n",
    "\n",
    "nep_con.download_experiment(\"trained\", destination=path_to_model, artifacts=\"states/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the \"X\" in the next line with the (saved) epoch you want to load\n",
    "\n",
    "path_to_ckpt = path_to_model + \"MOD-134/states/epoch=X.ckpt\"\n",
    "\n",
    "model = FreqNet.load_from_checkpoint(path_to_ckpt, data_object=db.fft)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Experiment-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
