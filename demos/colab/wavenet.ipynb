{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your GDrive \n",
    "In order to train the network on your data, create a directory named `data/`\n",
    "in the current working directory (cwd) of this notebook (when on colab and connected to gdrive\n",
    "this would be the `MyDrive/` directory in your gdrive account) and put audio files in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "# this set the cwd of the notebook\n",
    "%cd /gdrive/MyDrive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install `mimikit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mimikit==0.2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimikit as mmk\n",
    "import torch\n",
    "\n",
    "# DATA\n",
    "\n",
    "# list of files or directories to use as data (\"./\" is the cwd of the notebook)\n",
    "sources = ['./data']\n",
    "# audio sample rate\n",
    "sr = 16000\n",
    "# number of quantization levels (256 -> 8-bit)\n",
    "q_levels = 256\n",
    "\n",
    "# NETWORK\n",
    "\n",
    "# the number of layers determines 'how much past' is used to predict the next future step\n",
    "# here you can make blocks of layers by specifying a tuple of integers, e.g. (2, 3, 2)\n",
    "n_layers = (3,)\n",
    "# kernel_size is the size of the convolution. You can specify a single int for the whole\n",
    "# network or one size per layer\n",
    "kernel_size = (16, 8, 2)\n",
    "# how many parameters pro convolution layer\n",
    "gate_dim = 256\n",
    "# next arg can take 3 values : -1 -> input & output are summed at the end of the input,\n",
    "# 1 -> at the beginning, 0 -> they are not summed\n",
    "accum_outputs = 0\n",
    "# the next 2 args can take integers or None. Integers add skips and/or residuals layers of this size.\n",
    "# None adds no layers\n",
    "skip_dim = None\n",
    "residuals_dim = None\n",
    "\n",
    "# OPTIMIZATION\n",
    "\n",
    "# how many epochs should we train for\n",
    "max_epochs = 50\n",
    "# how many examples are used pro training steps\n",
    "batch_size = 16\n",
    "# the learning rate\n",
    "max_lr = 5e-4\n",
    "# betas control how fast the network changes its 'learning course'.\n",
    "# generally, betas should be close but smaller than 1. and be balanced with the batch_size :\n",
    "# the smaller the batch, the higher the betas 'could be'.\n",
    "betas = (0.9, 0.93)\n",
    "# one wavenet epoch can be very long, so as to monitor the net's progress,\n",
    "# we limit the number of batches pro epoch\n",
    "limit_train_batches = 1000\n",
    "\n",
    "# MONITORING\n",
    "\n",
    "# how often should the network generate during training\n",
    "every_n_epochs = 4\n",
    "# how many examples from random prompts should be generated\n",
    "n_examples = 3\n",
    "# how many steps (1 step = 1 sample) should be generated\n",
    "n_steps = 5 * sr\n",
    "# the sampling temperature changes outputs a lot!\n",
    "# roughly : prefer values close to 1. & hot -> noisy ; cold -> silence\n",
    "temperature = torch.tensor([.9, .999, 1.25]).unsqueeze(1)\n",
    "\n",
    "assert temperature.size(0) == n_examples, \"number of values in temperature must be equal to n_examples\"\n",
    "rf = mmk.WaveNet.rf(n_layers, kernel_size)\n",
    "print(\"arguments are ok! The network will have a receptive field of size :\", rf, \"samples\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = mmk.WaveNet.schema(sr, 0., q_levels)\n",
    "\n",
    "db_path = 'wavenet-demo.h5'\n",
    "print(\"collecting data...\")\n",
    "db = mmk.Database.create(db_path, sources, schema)\n",
    "if not len(db.qx.files):\n",
    "    raise ValueError(\"Empty db. No audio files were found...\")\n",
    "print(\"successfully created the db.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mmk.WaveNet(\n",
    "    **mmk.WaveNet.dependant_hp(db),\n",
    "    kernel_size=kernel_size,\n",
    "    gate_dim=gate_dim,\n",
    "    accum_outputs=accum_outputs,\n",
    "    residuals_dim=residuals_dim,\n",
    "    skip_dim=skip_dim,\n",
    "    n_layers=n_layers,\n",
    "    batch_size=batch_size,\n",
    "    batch_seq_length=rf * 2 if rf <= 128 else rf + rf // 4,\n",
    "    max_lr=max_lr,\n",
    "    betas=betas,\n",
    "    div_factor=5,\n",
    ")\n",
    "print(net.hparams)\n",
    "\n",
    "dm = mmk.DataModule(net, db,\n",
    "                    splits=tuple(),\n",
    "                    in_mem_data=True)\n",
    "\n",
    "cb = mmk.GenerateCallback(every_n_epochs, indices=[None] * n_examples,\n",
    "                          n_steps=n_steps,\n",
    "                          play_audios=True,\n",
    "                          plot_audios=True,\n",
    "                          temperature=temperature.to('cuda') if torch.cuda.is_available() else temperature)\n",
    "\n",
    "trainer = mmk.get_trainer(root_dir=None,\n",
    "                          max_epochs=max_epochs,\n",
    "                          callbacks=[cb],\n",
    "                          limit_train_batches=limit_train_batches,\n",
    "                          checkpoint_callback=False)\n",
    "print(\"here we go!\")\n",
    "trainer.fit(net, datamodule=dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ktonal.com/k-circle-bw.png\" alt=\"logo\" width=\"75\"/>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
