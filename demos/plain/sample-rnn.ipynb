{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook assumes you already installed mimikit on your system through the command-line\n",
    "```bash\n",
    "pip install mimikit==0.2.2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimikit as mmk\n",
    "import torch\n",
    "\n",
    "# DATA\n",
    "\n",
    "# list of files or directories to use as data\n",
    "sources = ['./data']\n",
    "# audio sample rate\n",
    "sr = 16000\n",
    "# number of quantization levels (256 -> 8-bit)\n",
    "q_levels = 256\n",
    "\n",
    "# NETWORK\n",
    "\n",
    "# how many samples each tier receives as input\n",
    "# stick to decreasing sequences, size_i must be divisible by size_i+1 and\n",
    "# last 2 numbers must be equal. You can have as many tiers as you want.\n",
    "frame_sizes = (16, 4, 4)\n",
    "# number of lstm network pro tier\n",
    "n_rnn = 2\n",
    "# dimensionality of the lstms\n",
    "dim = 512\n",
    "\n",
    "# OPTIMIZATION\n",
    "\n",
    "# how many epochs should we train for\n",
    "max_epochs = 50\n",
    "# how many examples are used pro training steps\n",
    "batch_size = 16\n",
    "# the learning rate\n",
    "max_lr = 5e-4\n",
    "# betas control how fast the network changes its 'learning course'.\n",
    "# generally, betas should be close but smaller than 1. and be balanced with the batch_size :\n",
    "# the smaller the batch, the higher the betas 'could be'.\n",
    "betas = (0.9, 0.93)\n",
    "\n",
    "# MONITORING\n",
    "\n",
    "# how often should the network generate during training\n",
    "every_n_epochs = 4\n",
    "# how many examples from random prompts should be generated\n",
    "n_examples = 3\n",
    "# how many steps (1 step = 1 sample) should be generated\n",
    "n_steps = 15 * sr\n",
    "# the sampling temperature changes outputs a lot!\n",
    "# roughly : prefer values close to 1. & hot -> noisy ; cold -> silence\n",
    "temperature = torch.tensor([.9, .999, 1.25]).unsqueeze(1).to('cuda')\n",
    "\n",
    "assert temperature.size(0) == n_examples, \"number of values in temperature must be equal to n_examples\"\n",
    "print(\"arguments are ok!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = mmk.SampleRNN.schema(sr, 0., q_levels)\n",
    "\n",
    "db_path = 'sample-rnn-demo.h5'\n",
    "print(\"collecting data...\")\n",
    "db = mmk.Database.create(db_path, sources, schema)\n",
    "print(\"successfully created the db.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create network and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mmk.SampleRNN(\n",
    "    feature=schema['qx'],\n",
    "    q_levels=q_levels,\n",
    "    frame_sizes=frame_sizes,\n",
    "    n_rnn=n_rnn,\n",
    "    dim=dim,\n",
    "    mlp_dim=dim,\n",
    "    batch_size=batch_size,\n",
    "    max_lr=max_lr,\n",
    "    betas=betas,\n",
    "    div_factor=5,\n",
    ")\n",
    "\n",
    "print(net.hparams)\n",
    "\n",
    "dm = mmk.DataModule(net, db,\n",
    "                    splits=tuple(),\n",
    "                    in_mem_data=True)\n",
    "\n",
    "cb = mmk.GenerateCallback(every_n_epochs, indices=[None] * n_examples,\n",
    "                          n_steps=n_steps,\n",
    "                          play_audios=True,\n",
    "                          plot_audios=True,\n",
    "                          temperature=temperature)\n",
    "\n",
    "trainer = mmk.get_trainer(root_dir=None,\n",
    "                          max_epochs=max_epochs,\n",
    "                          callbacks=[cb],\n",
    "                          checkpoint_callback=False)\n",
    "print(\"here we go!\")\n",
    "trainer.fit(net, datamodule=dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ktonal.com/k-circle-bw.png\" alt=\"logo\" width=\"75\"/>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
