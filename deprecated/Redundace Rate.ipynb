{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mimikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Source Code for Redundance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit.freqnet import FreqNetNetwork\n",
    "from mimikit.data import Database\n",
    "from mimikit.utils import audio, signal\n",
    "from mimikit import NeptuneConnector\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20, 6)\n",
    "\n",
    "\n",
    "# functions we need to compute the redundance rate\n",
    "\n",
    "\n",
    "def cosine_similarity(X, Y, eps=1e-10):\n",
    "    \"\"\"\n",
    "    safely computes the cosine similarity between matrices X and Y.\n",
    "\n",
    "    Shapes:\n",
    "    -------\n",
    "    X : (*, N, D)\n",
    "    Y : (*, M, D)\n",
    "    D_xy : (*, N, M)\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    The need for this function arises from the fact that torch.nn.CosineSimilarity only computes the \n",
    "    diagonal of D_xy, as in cosine_sim(output, target) \n",
    "    \"\"\"\n",
    "    if not isinstance(eps, torch.Tensor):\n",
    "        eps = torch.tensor(eps).to(X)\n",
    "        \n",
    "    dot_prod = torch.matmul(X, Y.transpose(-2, -1))\n",
    "    norms = torch.norm(X, p=2, dim=-1).unsqueeze_(-1) * torch.norm(Y, p=2, dim=-1).unsqueeze_(-2)\n",
    "    cos_theta = dot_prod / torch.maximum(norms, eps)    \n",
    "    return cos_theta\n",
    "\n",
    "def angular_distance(X, Y, eps=1e-10):\n",
    "    \"\"\"\n",
    "    angular distance is a valid distance metric based on the cosine similarity\n",
    "    see https://en.wikipedia.org/wiki/Cosine_similarity#Angular_distance_and_similarity\n",
    "    \n",
    "    Shapes:\n",
    "    -------\n",
    "    X : (*, N, D)\n",
    "    Y : (*, M, D)\n",
    "    D_xy : (*, N, M)\n",
    "    \"\"\"\n",
    "    if not isinstance(eps, torch.Tensor):\n",
    "        eps = torch.tensor(eps).to(X)\n",
    "        \n",
    "    def safe_acos(x):\n",
    "        # torch.acos returns nan near -1 and 1... see https://github.com/pytorch/pytorch/issues/8069\n",
    "        return torch.acos(torch.clamp(x, min=-1+eps/2, max=1-eps/2))\n",
    "\n",
    "    have_negatives = torch.any(X < 0) or torch.any(Y < 0)\n",
    "    cos_theta = cosine_similarity(X, Y, eps)\n",
    "    \n",
    "    pi = torch.acos(torch.zeros(1)).item() * 2\n",
    "    D_xy = (1 + int(not have_negatives)) * safe_acos(cos_theta) / pi\n",
    "    \n",
    "    return D_xy\n",
    "\n",
    "\n",
    "def nearest_neighbor(X, Y):\n",
    "    \"\"\"\n",
    "    computes nearest neighbor by angular distance\n",
    "    \"\"\"\n",
    "    D_xy = angular_distance(X, Y)\n",
    "    dists, nn = torch.min(D_xy, dim=-1)\n",
    "    return dists, nn\n",
    "\n",
    "\n",
    "def torch_frame(x, frame_size, hop_length):\n",
    "    \"\"\"\n",
    "    helper to reshape an array into frames\n",
    "    \"\"\"\n",
    "    N = x.size(-1)\n",
    "    org_size = x.size()[:-1]\n",
    "    tmp_0 = np.prod(tuple(org_size))\n",
    "    new_dims = (1 + int((N - frame_size) / hop_length), frame_size)\n",
    "    framed = torch.as_strided(x.reshape(-1, N), (tmp_0, *new_dims), (N, hop_length, 1))\n",
    "    return framed.reshape(*org_size, *new_dims)\n",
    "\n",
    "\n",
    "def repeat_rate(x, frame_size, hop_length):\n",
    "    \"\"\"\n",
    "    frames x and compute repeat-rate per frame\n",
    "    \"\"\"\n",
    "    framed = torch_frame(x, frame_size, hop_length)\n",
    "    uniques = torch.tensor([torch.unique(row).size(0) for row in framed.reshape(-1, framed.size(-1))])\n",
    "    return (1 - (uniques-1) / (frame_size-1)).reshape(framed.size()[:-1], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/redundance-rate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup DB & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nep_con = NeptuneConnector(user=\"k-tonal\",\n",
    "                           setup=dict(\n",
    "                               db=\"data-and-base-notebooks/DAT-55\",\n",
    "                               model=\"experiment-2/EX2-217\"\n",
    "                           ))\n",
    "db_name = \"MyMelodies.h5\"\n",
    "\n",
    "\n",
    "path_to_db = \"./\" + db_name\n",
    "path_to_model = \"./models/\"\n",
    "\n",
    "# uncomment the ones you need :\n",
    "\n",
    "# nep_con.download_experiment(\"model\", destination=path_to_model, artifacts=\"states/\")\n",
    "# db = nep_con.download_database(\"db\", db_name)\n",
    "\n",
    "# db = Database(path_to_db)\n",
    "\n",
    "db.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 99\n",
    "\n",
    "path_to_ckpt = path_to_model + nep_con.setup[\"model\"].split(\"/\")[-1] + \"/states/epoch=%i.ckpt\" % epoch\n",
    "model = FreqNetNetwork.load_from_checkpoint(path_to_ckpt, data_object=db.fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_length = 64\n",
    "n_steps = 2048\n",
    "\n",
    "\n",
    "# prompt index :\n",
    "\n",
    "i = randint(0, model.data.shape[0] - prompt_length)\n",
    "\n",
    "\n",
    "output = model.generate(model.data[i:i+prompt_length], time_domain=False, n_steps=n_steps).squeeze(0)\n",
    "wrt = torch.from_numpy(model.data[i+prompt_length:i+prompt_length+n_steps]).to(output).unsqueeze(0)\n",
    "\n",
    "audio(output.squeeze().numpy().T, hop_length=db.fft.attrs[\"hop_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute RR over time at mutiple levels for a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nearest neighbors:\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, neighbs = nearest_neighbor(output[:, prompt_length:], wrt)\n",
    "\n",
    "\n",
    "# for plotting multiple levels of locality, we have one hop_length for several frame_sizes\n",
    "frame_size = (8, 32, 128)\n",
    "hop_length = 2\n",
    "\n",
    "\n",
    "# compute rr and plot\n",
    "\n",
    "for fs in frame_size:\n",
    "    with torch.no_grad():\n",
    "        r = repeat_rate(neighbs, fs, hop_length)\n",
    "    plt.plot(r.squeeze().cpu().numpy(), label=\"frame size = \"+str(fs))\n",
    "    \n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1, 1.1])\n",
    "plt.legend()\n",
    "plt.ylabel('Redundance Rate')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Local Redundance Rate over Time')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate outputs for regularly spaced prompt indices\n",
    "\n",
    "> if, in the next cell, `n_prompts * n_steps` is too big, this will crash the RAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for all prompts :\n",
    "\n",
    "prompt_length = 64\n",
    "n_steps = 600\n",
    "\n",
    "# number of prompts we will score :\n",
    "\n",
    "n_prompts = 500\n",
    "\n",
    "# and their indices :\n",
    "\n",
    "indices = range(0, db.fft.shape[0]-prompt_length-n_steps, db.fft.shape[0] // n_prompts)\n",
    "\n",
    "# compute\n",
    "\n",
    "prompts = torch.from_numpy(np.stack([db.fft[i:i+prompt_length] for i in indices]))\n",
    "wrts = torch.from_numpy(np.stack([db.fft[i+prompt_length:i+prompt_length+n_steps] for i in indices]))\n",
    "\n",
    "outputs = model.generate(prompts, time_domain=False, n_steps=n_steps).squeeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the mean RR for each prompt index and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute nearest neighbors:\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, neighbs = nearest_neighbor(outputs[:, prompt_length:], wrts)\n",
    "\n",
    "\n",
    "# multiple levels of locality :\n",
    "\n",
    "frame_size = (8, 32, 64)\n",
    "hop_length = 1\n",
    "\n",
    "\n",
    "# compute rr and plot\n",
    "scores = {}\n",
    "for fs in frame_size:\n",
    "    with torch.no_grad():\n",
    "        r = repeat_rate(neighbs, fs, hop_length).mean(dim=-1)\n",
    "    scores[fs] = {i: x for i, x in zip(range(r.size(-1)), r.squeeze().cpu().numpy())}\n",
    "    plt.plot(list(indices), r.squeeze().cpu().numpy(), label=\"frame size = \"+str(fs))\n",
    "    \n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.1, 1.1])\n",
    "plt.ylabel('Mean Local Redundance Rate')\n",
    "plt.xlabel('Prompt Index')\n",
    "plt.title(\"Output's Scores\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen to the \"bests\" and \"worsts\" outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a frame_size :\n",
    "\n",
    "fs = frame_size[0]\n",
    "\n",
    "srtd = sorted(list(scores[fs].keys()), key=lambda k: scores[fs][k])\n",
    "bests = srtd[:4]\n",
    "worsts = srtd[-4:]\n",
    "\n",
    "print()\n",
    "print(\"Less redundants :\")\n",
    "print()\n",
    "\n",
    "for i in bests:\n",
    "    print(\"Prompt index =\", list(indices)[i], \"score =\", scores[fs][i])\n",
    "    audio(outputs[i].squeeze().numpy().T, hop_length=db.fft.attrs[\"hop_length\"])\n",
    "\n",
    "print()\n",
    "print(\"Most redundants :\")\n",
    "print()\n",
    "for i in worsts:\n",
    "    print(\"Prompt index =\", list(indices)[i], \"score =\", scores[fs][i])\n",
    "    audio(outputs[i].squeeze().numpy().T, hop_length=db.fft.attrs[\"hop_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select prompts closest to some target score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a target score :\n",
    "\n",
    "my_target_score = 0.555\n",
    "\n",
    "# pick a frame_size :\n",
    "\n",
    "fs = frame_size[0]\n",
    "\n",
    "srtd = sorted(list(scores[fs].keys()), key=lambda k: abs(scores[fs][k] - my_target_score))\n",
    "bests = srtd[:4]\n",
    "\n",
    "print()\n",
    "print(\"Closests to target score :\")\n",
    "print()\n",
    "\n",
    "for i in bests:\n",
    "    print(\"Prompt index =\", list(indices)[i], \"score =\", scores[fs][i])\n",
    "    audio(outputs[i].squeeze().numpy().T, hop_length=db.fft.attrs[\"hop_length\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
