{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Started\n",
    "=============\n",
    "\n",
    "Mimikit is a python package for composers and musicians to dive into sound generation and manipulation by machine learning tools. This guide will show you how to create a neural network that can learn and generate audio data. It is not required to have strong python coding skills to use Mimikit, though you will have to learn (or know) some basic principles of the python programming language. Using deep learning tools to synthesize sound requires a workflow quite different from current state-of-the-art synthesis platforms. It is also worth noting that it is not necessarily easy (or even possible) to control the process to get exactly the results you imagine. If you are in the mood for experiments or you just want to get a bit better understanding of neural audio synthesis, this is the right tool for you.\n",
    "\n",
    "For this guide, we will use ipython notebooks as it is the easiest and most convenient way to work with mimikit. It is important to understand that deep learning cannot be done efficiently on a CPU. Deep learning is mostly done by using a GPU (graphics processing unit). While it is not impossible to run models on a CPU, it will simply take too long to train any meaningful network. For anybody who does not own a GPU (or does not know how to set up the environment to run computations on it), we recommend using Google Colab (you will need to have a google account). Colab is an online platform that allows users to create and run ipython notebooks on a GPU and it is free of charge. The amount of time and memory you can use on Colab is limited, but to get started with mimikit and train some models, Colab will work just fine. We will now open this guide as a notebook in Colab.\n",
    "\n",
    "1.  Sign up for a google account if you don't already have one.\n",
    "2.  go to https://colab.research.google.com/notebooks/intro.ipynb and sign in with your google account\n",
    "3.  Select \"Open notebook\" from the \"file\" menu item\n",
    "4.  Select \"github\" and enter \"k-tonal/mimikit-notebooks\" into the textbox (as seen in the image below)\n",
    "5.  Find the file \"Getting_Started.ipynb\" from the list and click on it. \n",
    "\n",
    "![](imgs/find-mmk-notebooks.jpg \"get notebooks from github\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using mimikit on colab\n",
    "---------------------------------\n",
    "\n",
    "Ipython notebooks are structured into \"Cells\". A \"Cell\" contains either text or executable code. You can recognize the code cells by the formatting and the two square brackets on the left of the Cell [ ] If you click on the square brackets the code in the cell will be executed. But before doing so, let's make sure that we are set up to use a GPU. Go to the menu and select \"Runtime\" -> \"Change runtime type\". A popup will appear in which you can select \"GPU\" as your hardware accelerator.\n",
    "\n",
    "Now we are ready to run some code. To use mimikit in a notebook it first needs to be installed into the Colab runtime. This is done by running the following cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the mimikit package\n",
    "\n",
    "!pip install mimikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements\n",
    "---------------------------\n",
    "\n",
    "Python uses a module system.  To use classes and functions defined in a package they need to be imported.  We import a couple of things here and use them in the comming steps of this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit import get_trainer\n",
    "from mimikit.data import Database, freqnet_db\n",
    "from mimikit.freqnet import FreqNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect your Gdrive (google drive)\n",
    "---------------------------------------------------\n",
    "We need a place to upload sound files and to save results. Colab itself has some memory for saving and exchanging data, but it is volatile and disappears as soon as the Colab runtime is disconnected. We highly recommend avoiding to save anything there and use google drive instead. Everything you upload to your Gdrive as well as everything saved by mimikit on your Gdrive will remain there until you decide to delete it.\n",
    "\n",
    "If you run the following cell you will be directed to a link to authorize Colab to access your Gdrive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My\\ Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare audio data for training a model\n",
    "--------------------------------------------------------\n",
    "\n",
    "We are going to train a FreqNet model. FreqNet is a neural network that is trained on audio data in the frequency domain. After training the model can generate data that should resemble the data it was trained on. Sometimes it recreates parts of the data unaltered and sometimes it might go into loops or jump around and stretch and compress material in time.\n",
    "\n",
    "To train the model we need to convert some sound files into a format that FreqNet can read. Let's assume you have a soundfile called 'cat_sounds.wav' you want to use as training data (but of course you can select any files you want).\n",
    "\n",
    "First, we need to upload our soundfile, then we can run the following cell to create an H5 file (which is a convenient format that FreqNet can read).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a H5 file called cat_sounds.h5 from all audio files found in the musicdata folder\n",
    "\n",
    "db = freqnet_db('cat_sounds.h5', roots=['musicdata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a FreqNet object and prepare for training\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "FreqNet has parameters that specify the details of the model architecture.  The speed at which the model learns and the characteristics of the outputs it will produce depend on the given parameters.  To learn more about the FreqNet architecture look [here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FreqNet(data_object=db.fft,\n",
    "                model_dim=1024,\n",
    "                groups=1,\n",
    "                n_layers=(4,),\n",
    "                with_skip_conv=False,\n",
    "                with_residual_conv=False,\n",
    "                accum_outputs=0,\n",
    "                concat_outputs=0,\n",
    "                pad_input=0)\n",
    "\n",
    "trainer = get_trainer(max_epochs=100,\n",
    "                      epochs=[30, 60, 99],\n",
    "                      root_dir=path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training\n",
    "-------------------------\n",
    "\n",
    "This will take quite some time (depending on the size of the input data and the model parameters).\n",
    "For five minutes of audio data, this could range anywhere between maybe 4 to 10 hours.  You can spend this time starring at the progress bar or find something else to do.  See you in a couple of hours for the next part of the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
