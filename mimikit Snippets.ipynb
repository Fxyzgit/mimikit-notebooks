{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mimikit Snippets <a id=\"TOP\" name=\"TOP\"></a>\n",
    "\n",
    "This is a collection of small self-contained code snippets that you can copy & paste in your notebook.\n",
    "\n",
    "\n",
    "> **Note**: This notebook is only for reference and not to be evaluated as is.\n",
    "\n",
    "For an example of how to build your own notebook, checkout the [base `FreqNet` notebook]()\n",
    "\n",
    "For documentation on the freqnet package and its classes checkout [this link]()\n",
    "\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "- O. [Setup](#O.)\n",
    "    - a) [Installation](#Oa)\n",
    "    - b) [connect to Gdrive (colab)](#Ob)\n",
    "    - c) [setup neptune](#Oc)\n",
    "    - d) [variables](#Od)\n",
    "\n",
    "\n",
    "- I. [Database](#I.)\n",
    "    - a) [make a Database](#Ia)\n",
    "    - b) [get data from a database](#Ib)\n",
    "\n",
    "\n",
    "- II. [Training](#II.)\n",
    "    - a) [configure](#IIa)\n",
    "    - b) [train](#IIb)\n",
    "    - c) [plot the losses](#IIc)\n",
    "    - d) [open tensorboard](#IId)\n",
    "    - e) [load checkpoint](#IIe)\n",
    "    - f) [resume training](#IIf)\n",
    "    - g) [manually save checkpoint](#IIg)\n",
    "\n",
    "\n",
    "- III. [Sampling](#III.)\n",
    "    - a) [generate](#IIIa)\n",
    "    - b) [manual prompt](#IIIb)\n",
    "    - c) [automatic prompt](#IIIc)\n",
    "    - d) [random prompt](#IIId)\n",
    "    - e) [same prompt(s) for several models](#IIIe)\n",
    "    - f) [log audio](#IIIf)\n",
    "    - g) [plot the outputs](#IIIg)\n",
    "    \n",
    "\n",
    "\n",
    "- IV. [Neptune](#IV.)\n",
    "    - a) [configure](#IVa)\n",
    "    - b) [available methods](#IVb)\n",
    "    - c) [access Experiment object after training](#IVc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup <a id=\"O.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Installation <a id=\"Oa\"></a><a name=\"Oa\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on your PC in a terminal :\n",
    "pip install mimikit\n",
    "\n",
    "# in any notebook (colab or otherwise) :\n",
    "!pip install mimikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) connect to GDrive (colab) <a id=\"Ob\"></a><a name=\"Ob\"></a>\n",
    "this is pasted from the colab snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) setup neptune <a id=\"Oc\"></a><a name=\"Oc\"></a>\n",
    "\n",
    "this shows how to setup neptune within a noteboook. For how to setup neptune on your computer, check out the [Step-by-step neptune notebook](https://colab.research.google.com/github/k-tonal/mimikit-notebooks/blob/main/Step-by-step%20neptune.ipynb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit import NeptuneConnector\n",
    "\n",
    "nep_con = NeptuneConnector(user=\"MimiK_it\",\n",
    "                           setup={\"db\": \"mimikit-demo/MMK-03\",\n",
    "                                  \"model\": \"mimikit-demo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) variables <a id=\"Od\"></a> <a name=\"Od\"></a>\n",
    "\n",
    "Throughout the snippets we use consistent variable names.\n",
    "\n",
    "Here we pseudo-exemplify them for reference.\n",
    "\n",
    "It is _strongly advised_ to have a similar cell at the begining of your notebook with your own values and \"build\" your notebook through copying, pasting & adapting the snippets listed below.\n",
    "\n",
    "This will protect you against typos and mistakes and allow you to use the notebooks' cells as small modules within a well-defined environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_audio_files = \"MyPc/home/my_audios\"\n",
    "\n",
    "path_to_db = \"directory/db.h5\"\n",
    "\n",
    "# where files are stored :\n",
    "path_to_model = \"home/mimikit-models/\"\n",
    "\n",
    "path_to_ckpt = path_to_model + \"/states/epoch=X.ckpt\"\n",
    "\n",
    "# 3 main objects are db, model and trainer :\n",
    "db = Database(path_to_db)\n",
    "model = ModelClass(....)\n",
    "trainer = get_trainer(root_dir=path_to_model, ....)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. BUILD AND USE `Database`<a id=\"I.\"></a><a name=\"I.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Make a DB <a id=\"Ia\"></a><a name=\"Ia\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1 : with a python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit.data import freqnet_db\n",
    "\n",
    "freqnet_db(path_to_db,\n",
    "           roots=[\"directory/\"],\n",
    "          files=[\"file1\", \"file2\"],\n",
    "           # those are the defaults and can be omitted :\n",
    "          n_fft=2048,\n",
    "          hop_length=512,\n",
    "          sample_rate=22050,\n",
    "           # specifying a neptune_path (\"account/project\" and optionally + \"/EXP-ID\") \n",
    "           # automatically upload the db to this path (either updating an existing experiment \n",
    "           # or creating a new one)\n",
    "          neptune_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 : with a command-line (once you pip installed mimikit)\n",
    "\n",
    "in a terminal, after having installed mimikit\n",
    "this takes exactly the same arguments as the function in Option 1 :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqnet-db \"new_db.h5\" --roots \"directory/\" --files \"file1\" \"file2\" --n-fft 1024 --hop-length 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for usage and flags shorthands type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqnet-db --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3 : manually build a FileWalker and an extract function! chekout mimikit.freqnet.freqnet_db for an example!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) get data from a db <a id=\"Ib\"></a><a name=\"Ib\"></a>\n",
    "\n",
    "`Database` keeps the files flatten in a large array under a feature attribute (in `freqnet_db`s the FFTs are in the `db.fft` attribute) which can be indexed like a `numpy` array.\n",
    "\n",
    "In addition, the positions of each file in the flatten array is stored in `db.metadata`, a `pandas.Dataframe` with the `columns` `[\"name\", \"start\", \"stop\", \"duration\"]`. Each row of `db.metadata` corresponds to one extracted file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit.data import Database\n",
    "\n",
    "db = Database(path_to_db)\n",
    "\n",
    "# assuming the db is a freqnet-db,\n",
    "# retrieve from frame 5 to frame 10 :\n",
    "\n",
    "frames = db.fft[5:10]\n",
    "\n",
    "# retrieve a whole file :\n",
    "\n",
    "file_array = db.fft.get(db.metadata.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Training <a id=\"II.\"></a><a name=\"II.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) configure <a id=\"IIa\"></a><a name=\"IIa\"></a>\n",
    "\n",
    "`get_trainer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit import get_trainer\n",
    "\n",
    "trainer = get_trainer(# where to store the files :\n",
    "                      root_dir=path_to_model,\n",
    "                      # how often to save checkpoint :\n",
    "                      epochs=10,\n",
    "                      # train for how many epochs :\n",
    "                      max_epochs=50)\n",
    "\n",
    "# if you configured neptune just add 2 arguments :\n",
    "\n",
    "trainer = get_trainer(# where to store the files :\n",
    "                      root_dir=path_to_model,\n",
    "                      # how often to save checkpoint :\n",
    "                      epochs=10,\n",
    "                      # train for how many epochs :\n",
    "                      max_epochs=50,\n",
    "                      # model and NeptuneConnector :\n",
    "                      model=model,\n",
    "                      neptune_connector=nep_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) train <a id=\"IIb\"></a><a name=\"IIb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) plot the losses <a id=\"IIc\"></a><a name=\"IIc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) open tensorboard <a id=\"IId\"></a><a name=\"IId\"></a>\n",
    "\n",
    "assuming `path_to_model=\"./\"` and you are in a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) load checkpoint <a id=\"IIe\"></a><a name=\"IIe\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT : all models in mimikit.freqnet need a data_object argument when reloading\n",
    "\n",
    "from mimikit.freqnet import FreqNet\n",
    "from mimikit.data import Database\n",
    "\n",
    "db = Database(path_to_db)\n",
    "model = FreqNet.load_from_checkpoint(path_to_ckpt, data_object=db.fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) resume training from checkpoint <a id=\"IIf\"></a><a name=\"IIf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class you want to load\n",
    "\n",
    "from mimikit.freqnet import FreqNet\n",
    "from mimikit import get_trainer\n",
    "\n",
    "\n",
    "# FreqNetModel needs a valid data_object when loading :\n",
    "\n",
    "model = FreqNet.load_from_checkpoint(path_to_ckpt, data_object=db.fft)\n",
    "\n",
    "# this resume training from a model checkpoint (path_to_ckpt) \n",
    "# and the last_optim_state.pt in the states/ directory\n",
    "\n",
    "trainer = get_trainer(model=model,\n",
    "                      resume_from_checkpoint=path_to_ckpt,\n",
    "                      # if ckpt was made at epoch=25, \n",
    "                      # the following will train for 25 more epochs:\n",
    "                      max_epochs=50,\n",
    "                      epochs=10,\n",
    "                      root_dir=path_to_model,\n",
    "                      )\n",
    "\n",
    "# trainer.fit(fnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) manually save checkpoint <a id=\"IIg\" name=\"IIg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# add a checkpoint in the model's states/ directory (where they belong...)\n",
    "\n",
    "trainer.save_checkpoint(os.path.join(trainer.default_root_dir, \"states\", \"test.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Sampling <a id=\"III.\" name=\"III.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) generate <a id=\"IIIa\" name=\"IIIa\"></a>\n",
    "\n",
    "the cells below show you how to define `prompt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(prompt, n_steps=2048,\n",
    "                        hop_length=db.fft.attrs[\"hop_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) manual prompt <a id=\"IIIb\" name=\"IIIb\"></a>\n",
    "\n",
    "`Database` stores all files in flat array. Informations about the files you extracted are stored in `db.metadata` which is a `panda.Dataframe`.\n",
    "You can then pick prompts anywhere in the db or in specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database(path_to_db)\n",
    "\n",
    "# in all cases we get the length of the prompt from the model \n",
    "\n",
    "prompt_length = model.receptive_field\n",
    "\n",
    "# anywhere in the db :\n",
    "\n",
    "# this need to be smaller than db.fft.shape[0] - prompt_length\n",
    "start_index = 1234\n",
    "\n",
    "# in a specific file :\n",
    "\n",
    "file = db.metadata.iloc[[3]]\n",
    "# start index relative to the beginning of the file\n",
    "start_index = 1234 + file[\"start\"].item()\n",
    "\n",
    "# finally \n",
    "\n",
    "prompt = db.fft[start_index:start_index+prompt_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) automatic prompts <a id=\"IIIc\" name=\"IIIc\"></a>\n",
    "simple trick to sample throughout a db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Database(path_to_db)\n",
    "N = db.fft.shape[0]\n",
    "prompt_length = model.receptive_field\n",
    "\n",
    "# how many prompts you want\n",
    "n_prompts = 40\n",
    "\n",
    "for i in range(0, N, N // n_prompts):\n",
    "    prompt = db.fft[i:i+prompt_length]\n",
    "\n",
    "#     then most likely :\n",
    "#     output = model.generate(prompt, 1000, hop_length=db.fft.attrs[\"hop_length\"])\n",
    "#     model.log_audio(output, \"prompt=%i\" % i, sample_rate=db.fft.attrs[\"sr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) random prompt <a id=\"IIId\" name=\"IIIVd\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all freqnets have methods to get random train and val examples :\n",
    "\n",
    "# train :\n",
    "\n",
    "prompt = model.random_train_example()\n",
    "\n",
    "# validation :\n",
    "\n",
    "prompt = model.random_val_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) same prompt(s) for several models <a id=\"IIIe\" name=\"IIIe\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just as an example :\n",
    "\n",
    "from random import randint\n",
    "import os\n",
    "\n",
    "db = Database(path_to_db)\n",
    "n_prompts = 10\n",
    "prompts_indices = [randint(0, db.fft.shape[0]) for _ in range(n_prompts)]\n",
    "# how many steps we want to generate :\n",
    "n_steps = 1000\n",
    "\n",
    "all_checkpoints = os.listdir(os.path.join(path_to_model, \"states\"))\n",
    "\n",
    "for ckpt in all_checkpoints:\n",
    "    # load the model\n",
    "    path_to_ckpt = os.path.join(path_to_model, \"states\", ckpt)\n",
    "    model = FreqNet.load_from_checkpoint(path_to_ckpt)\n",
    "\n",
    "    # loop through the prompts \n",
    "    for i in prompts_indices:\n",
    "        prompt = db.fft[i:i+model.receptive_field]\n",
    "        output = model.generate(prompt, n_steps, hop_length=db.fft.attrs[\"hop_length\"])\n",
    "        model.log_audio(output, \"prompt=%i\" % i, sample_rate=db.fft.attrs[\"sr\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) log audio <a id=\"IIIf\"></a><a name=\"IIIf\"></a>\n",
    "\n",
    "These method will always save an audio file in `path_to_model/audios`\n",
    "& in any neptune or TestTube loggers / experiments if the model is bound to some or if you passed some through\n",
    "the `experiments=[...]` keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some audio tensor as reutrned by FreqNet.generate(...)\n",
    "audio_tensor = torch.randn(1, 10000)\n",
    "audio_filename = \"name_of_the_file_you_want_to_create\"\n",
    "\n",
    "# if model just have been trained with some loggers:\n",
    "model.log_audio(audio_filename, audio_tensor)\n",
    "\n",
    "# if the data was made with non-default sample-rate :\n",
    "model.log_audio(audio_filename, audio_tensor, sample_rate=db.fft.attrs[\"sr\"])\n",
    "\n",
    "# if you want to log to specific Experiment objects (neptune or testtube)\n",
    "model.log_audio(audio_filename, audio_tensor, experiments=[neptune_exp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) plot the outputs <a id=\"IIIg\" name=\"IIIg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. plot in time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mimikit.utils import audio\n",
    "from librosa.display import waveplot\n",
    "\n",
    "prompt = model.random_train_example()\n",
    "\n",
    "output = model.generate(prompt, n_steps=2048,\n",
    "                        hop_length=db.fft.attrs[\"hop_length\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "waveplot(output.squeeze().numpy())\n",
    "\n",
    "audio(output.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. plot in freq domain\n",
    "(Be careful not to mix up the outputs variable afterwards!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mimikit.utils import audio, show, signal\n",
    "\n",
    "\n",
    "prompt = model.random_train_example()\n",
    "\n",
    "freq_output = model.generate(prompt, n_steps=2048,\n",
    "                        hop_length=db.fft.attrs[\"hop_length\"],\n",
    "                        time_domain=False).squeeze().cpu().numpy().T\n",
    "\n",
    "output = signal(freq_output)\n",
    "\n",
    "plt.figure(figsize=(24, 6))\n",
    "show(freq_output)\n",
    "\n",
    "audio(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Neptune <a id=\"IV.\"></a><a name=\"IV.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) configure <a id=\"IVa\"></a><a name=\"IVa\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimikit import NeptuneConnector\n",
    "\n",
    "# for downloading a db and creating a model experiment :\n",
    "\n",
    "nep_con = NeptuneConnector(user=\"mimi\",\n",
    "                           setup=dict(db=\"data/DAT-01\",\n",
    "                                      model=\"freqnets\"))\n",
    "\n",
    "# `setup` is mutable :\n",
    "\n",
    "nep_con.setup[\"model\"] += \"/FRQ-10\"\n",
    "\n",
    "# now you would have this exact setup :\n",
    "\n",
    "nep_con = NeptuneConnector(user=\"mimi\",\n",
    "                           setup=dict(db=\"data/DAT-01\",\n",
    "                                      model=\"freqnets/FRQ-10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) available methods <a id=\"IVb\"></a><a name=\"IVb\"></a>\n",
    "\n",
    "all methods of the `NeptuneConnector` take a `setup_key` argument for specifying \"where\" the method should happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stuff you can do with dbs : \n",
    "\n",
    "db = nep_con.download_database(\"db\", \"demo_db.h5\", destination=\"./\")\n",
    "\n",
    "# \"db\" is the setup_key, `db` the object to be uploaded\n",
    "\n",
    "nep_con.upload_database(\"db\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"model\" is the setup_key, `model` is the object or a path to the root_dir of such an object\n",
    "\n",
    "# with an object \n",
    "\n",
    "nep_con.upload_model(\"model\", model)\n",
    "\n",
    "# with a path\n",
    "\n",
    "nep_con.upload_model(\"model\", \"experiment-5/version_101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get, create or download experiments with just a setup_key\n",
    "\n",
    "exp = nep_con.get_experiment(\"model\")\n",
    "\n",
    "exp = nep_con.create_experiment(\"model\")\n",
    "\n",
    "# this download all the experiment's artifacts in a folder named after the experiment's id :\n",
    "\n",
    "exp = nep_con.download_experiment(\"model\")\n",
    "\n",
    "# download_experiment takes also `artifacts` as argument :\n",
    "\n",
    "exp = nep_con.download_experiment(\"model\", artifacts=\"audios/\")\n",
    "exp = nep_con.download_experiment(\"model\", artifacts=\"states/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) access `Experiment` object after training <a id=\"IVc\" name=\"IVc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model will have 2 loggers when neptune is turned-on and each logger has its own Experiment object.\n",
    "\n",
    "experiment = model.logger.experiment \n",
    "# can then be a list of several Experiment objects....\n",
    "\n",
    "# if you just want the neptune one :\n",
    "\n",
    "experiment = model.neptune_experiment\n",
    "\n",
    "# then, you can log, download, upload what you want :\n",
    "\n",
    "experiment.log_text(\"model_class\", \"FreqNet\")\n",
    "\n",
    "# you will get .zip with the next method. To download & unzip, use `NeptuneConnector.download_experiment`\n",
    "\n",
    "experiment.download_artifacts(\"/audios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. LOOK AT THE LOGS <a id=\"IV.\" name=\"IV.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listen to logged Audios\n",
    "\n",
    "If you logged audios in tensorboard or neptune, you can listen to them in there respective interfaces.\n",
    "\n",
    "Otherwise, the audios are still in your path_to_model/audios and you can play them in a notebook like so :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "from mimikit.utils import audio\n",
    "\n",
    "path_to_audios = os.path.join(path_to_model, \"audios\")\n",
    "\n",
    "for audio_file in os.listdir(path_to_audios):\n",
    "    signal, _ = librosa.load(audio_file)\n",
    "    print(audio_file)\n",
    "    audio(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#TOP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
